#' Parse Recorder Activity From Log Files
#'
#' Reads log files created by acoustic monitors and determines their status
#' throughout a specified monitoring period. This information is essential for
#' interpreting patterns of bat activity because it effectively amounts to the
#' sampling effort. In other words, did you record no bats that night because
#' there were no bats, or because the monitor had run out of batteries...
#'
#' @section Note: this function is currently only capable of parsing log files
#'   generated by either Wildlife Acoustics SM3 or SM4 or Titley Anabat Swift
#'   bat recorders.
#'
#' @section Note: To work as expected, log files must be renamed following the
#'   conventions outlined below!
#'
#'   \strong{Wildlife Acoustics:} These files should be renamed so that each
#'   file name begins with the site name followed by a hyphen and any additional
#'   information (e.g. date) that is desired in the file name. For example:
#'   "site_1-2019.txt". The hyphen and all characters that follow it will be
#'   disregarded. The site name should match the site name assigned in GUANO
#'   metadata so that the log file data is appropriately matched with the
#'   acoustic data.
#'
#'   \strong{Anabat Swift:} These files do not need to be renamed, but files for
#'   each site should be placed in their own sub-folder. The folder name should
#'   match the site name assigned in the GUANO metadata of the corresponding WAV
#'   files so they can be matched.
#'
#'   \strong{Anabat Ranger:} These files should be organised in the same way as
#'   those of the Anabat Swift described above.
#'
#' @param log_path Character. Path to directory containing log files generated
#'   by a Wildlife Acoustics SM3 or SM4 or Titley Anabat Swift bat recorder,
#'   organised as outlined above.
#' @param data_path Character. Path to an RData file to add activity data to.
#'   Optional, a save location will be created before data are saved.
#' @param monitoring_start Character. A date in the format "YYYY-MM-DD".
#'   Optional: use to specify a monitoring start date prior to the earliest date
#'   for which a log file exists.
#' @param monitoring_end Character. A date in the format "YYYY-MM-DD". Optional:
#'   use to specify a monitoring end date prior to the earliest date for which a
#'   log file exists.
#'
#' @return An RData file containing a data.frame of recorder activity.
#' @export
#'
#' @family import tools
#'
#' @examples \dontrun{
#' #' import_logs("C:/Folder/Folder/logss_Folder", "C:/Folder/Folder/Data.RData", "2021-01-01", "2021-12-31)
#' }
#'
import_logs <- function(log_path, data_path = NULL, monitoring_start = NULL, monitoring_end = NULL) {
  # Validate inputs
  if (!dir.exists(log_path)) {
    stop(
      "Log path does not exist: '", log_path, "'.\n",
      "Please check the path and try again."
    )
  }

  if (!is.null(monitoring_start)) {
    tryCatch(
      monitoring_start <- as.Date(monitoring_start),
      error = function(e) stop("Invalid monitoring_start date. Use format 'YYYY-MM-DD'.")
    )
  }

  if (!is.null(monitoring_end)) {
    tryCatch(
      monitoring_end <- as.Date(monitoring_end),
      error = function(e) stop("Invalid monitoring_end date. Use format 'YYYY-MM-DD'.")
    )
  }

  data_path <- .check_data_path(data_path, action = "New", object = "active_dates")
  # Find log files for each recorder type with proper regex patterns
  wa_file_list <- list.files(log_path,
    recursive = TRUE,
    pattern = "\\.txt$", # Wildlife Acoustics summary files
    full.names = TRUE,
    ignore.case = TRUE
  )
  swift_file_list <- list.files(log_path,
    recursive = TRUE,
    pattern = "log \\d{4}-\\d{2}-\\d{2}\\.csv$", # Anabat Swift daily logs
    full.names = TRUE
  )
  ranger_file_list <- list.files(log_path,
    recursive = TRUE,
    pattern = "ranger.*\\.csv$", # Anabat Ranger logs
    full.names = TRUE,
    ignore.case = TRUE
  )
  # Check if any log files were found
  if (length(wa_file_list) == 0 && length(swift_file_list) == 0 && length(ranger_file_list) == 0) {
    stop(
      "No log files found in '", log_path, "'.\n",
      "Please ensure the directory contains Wildlife Acoustics .txt files, ",
      "Anabat Swift log files, or Anabat Ranger log files."
    )
  }

  wa_active_dates <- NULL
  swift_active_dates <- NULL
  ranger_active_dates <- NULL
  if (length(wa_file_list) > 0) {
    wa_active_dates <- batr:::.read_wa_logs(wa_file_list, log_path)
  }
  if (length(swift_file_list) > 0) {
    swift_active_dates <- batr:::.read_swift_logs(swift_file_list, log_path)
  }
  if (length(ranger_file_list) > 0) {
    ranger_active_dates <- batr:::.read_ranger_logs(ranger_file_list, log_path)
  }
  active_dates <- do.call(rbind, Filter(Negate(is.null), list(
    wa_active_dates,
    swift_active_dates,
    ranger_active_dates
  )))

  # Fill in gaps for dates with no log entries
  active_dates <- .gap_generator(active_dates, monitoring_start, monitoring_end)

  .save_to_RDATA(active_dates, data_path)

  message(sprintf(
    "\nLog import complete: %d locations across %d dates.",
    length(unique(active_dates$Location)),
    length(unique(active_dates$Date))
  ))

  invisible(active_dates)
}

#' Parse Wildlife Acoustics Log Files
#'
#' Reads Wildlife Acoustics SM3/SM4 summary text files and extracts recording
#' activity dates per location.
#'
#' @param wa_file_list Character vector of full paths to Wildlife Acoustics .txt files.
#' @param log_path Character. Root directory containing log files (used for messaging).
#'
#' @return Data.frame with columns: Date, Location, Log_Count.
#'
#' @keywords internal
.read_wa_logs <- function(wa_file_list, log_path) {
  message("Wildlife Acoustics summary files found. Reading files:")
  output <- data.table::rbindlist(
    sapply(wa_file_list,
      data.table::fread,
      simplify = FALSE,
      select = c("DATE", "TIME")
    ),
    use.names = TRUE, idcol = "FileName", fill = TRUE
  )
  # Remove rows that don't match the regular date expression
  output <- output[grepl("^\\d{4}-[a-zA-Z]{3}-\\d{2}$", output$DATE), ]
  output$DATE <- lubridate::ymd(output$DATE)
  # Parse time with explicit UTC timezone (log files typically use local time,
  # but we only care about hour for day/night determination)
  output$Time <- as.POSIXct(output$TIME, format = "%H:%M:%S", tz = "UTC")

  # Assign recordings to "night" using noon-to-noon convention:
  # recordings after noon (hour > 11) belong to that date's night,
  # recordings before noon belong to the previous night
  output <- dplyr::mutate(output,
    night = ifelse(lubridate::hour(Time) > 11,
      DATE,
      DATE - 1
    ),
    night = as.Date(night)
  )
  # Derive location from file name: take basename then substring before first '-'
  # Simpler and more robust than nested vapply calls (avoids type coercion errors)
  file_names <- basename(output$FileName)
  output$Location <- sub("-.*$", "", file_names)
  output$Location <- gsub("_", " ", output$Location)

  # Aggregate by night and location (handles duplicate entries from multiple files)
  wa_active_dates <- as.data.frame(table(output$night, output$Location))
  colnames(wa_active_dates) <- c("Date", "Location", "Log_Count")
  wa_active_dates$Date <- lubridate::ymd(wa_active_dates$Date)

  return(wa_active_dates)
}

#' Parse Anabat Swift Log Files
#'
#' Reads Anabat Swift daily log CSV files and determines if the recorder was
#' functioning properly on each date based on microphone status and file counts.
#'
#' @param swift_file_list Character vector of full paths to Anabat Swift log files.
#' @param log_path Character. Root directory containing log files (used for messaging).
#'
#' @return Data.frame with columns: Date, Location, Log_Count.
#'
#' @keywords internal
.read_swift_logs <- function(swift_file_list, log_path) {
  message("Anabat Swift log files found. Reading files:")
  output <- as.data.frame(swift_file_list)
  output$Date <- strptime(gsub(".*/", "", output$swift_file_list), "log %Y-%m-%d")
  output$Location <- vapply(
    strsplit(output$swift_file_list, "/"),
    function(x) x[length(x) - 1], character(1)
  )
  output$Active <- NA_character_

  # Thresholds for determining if recorder was functioning properly
  MIC_FAIL_THRESHOLD <- 1 # More than 1 mic check message indicates problem
  MIN_FILES_THRESHOLD <- 10 # Minimum files expected if recording actively

  for (i in seq_along(output$swift_file_list)) {
    file <- output$swift_file_list[i]
    file_data <- read.csv(file, header = TRUE)
    mic_fails <- length(grep("Status: Check microphone", file_data[, 3]))
    files <- length(grep("FILE", file_data[, 2]))
    recording <- any(grepl("Status: Recording now", file_data[, 3]))

    if (mic_fails > MIC_FAIL_THRESHOLD && files < MIN_FILES_THRESHOLD) {
      output$Active[i] <- "N"
    } else if (mic_fails > MIC_FAIL_THRESHOLD || isFALSE(recording)) {
      output$Active[i] <- "N"
    } else {
      output$Active[i] <- "Y"
    }
  }

  output$Date <- as.Date(output$Date)
  # Replace any remaining NAs in Active column with "N"
  output$Active[is.na(output$Active)] <- "N"
  output$Log_Count <- ifelse(output$Active == "Y", 1, 0)

  # Aggregate by Date and Location (handles duplicates if multiple logs per day)
  output <- output[, c("Date", "Location", "Log_Count")]
  output <- stats::aggregate(Log_Count ~ Date + Location, data = output, FUN = max)

  return(output)
}

#' Parse Anabat Ranger Log Files
#'
#' Reads Anabat Ranger log CSV files and determines if the recorder was
#' functioning properly based on microphone status checks and recording activity.
#'
#' @param ranger_file_list Character vector of full paths to Anabat Ranger log files.
#' @param log_path Character. Root directory containing log files (used for messaging).
#'
#' @return Data.frame with columns: Date, Location, Log_Count.
#'
#' @keywords internal
.read_ranger_logs <- function(ranger_file_list, log_path) {
  message("Ranger log files found. Reading files:")
  output <- as.data.frame(ranger_file_list)
  output$Date <- strptime(
    sub("-\\d+\\-", "-", basename(output$ranger_file_list)),
    "ranger-%Y-%m-%d"
  )
  output$Location <- vapply(
    strsplit(output$ranger_file_list, "/"),
    function(x) x[length(x) - 1], character(1)
  )
  output$Active <- NA_character_

  # Thresholds for determining if recorder was functioning properly
  MIC_FAIL_THRESHOLD <- 1 # More than 1 mic check message indicates problem
  MIN_FILES_THRESHOLD <- 10 # Minimum files expected if recording actively

  for (i in seq_along(output$ranger_file_list)) {
    file <- output$ranger_file_list[i]
    # Ranger log files can have variable column counts; read flexibly
    file_data <- tryCatch(
      read.csv(
        file,
        header = FALSE,
        stringsAsFactors = FALSE,
        blank.lines.skip = TRUE,
        fill = TRUE
      ),
      error = function(e) data.frame()
    )
    # If unreadable, mark inactive and continue
    if (ncol(file_data) == 0 || nrow(file_data) == 0) {
      output$Active[i] <- "N"
      next
    }
    # Assign canonical names to first four columns if present
    base_names <- c("Date", "Message_Type", "Function", "Note")
    colnames(file_data)[seq_len(min(length(base_names), ncol(file_data)))] <- base_names[seq_len(min(length(base_names), ncol(file_data)))]
    # Determine which column holds the free-form status text (prefer 'Note', else last column)
    note_col <- if ("Note" %in% names(file_data)) "Note" else names(file_data)[ncol(file_data)]
    note_vec <- file_data[[note_col]]
    mic_fails <- length(grep("Status: Check mic", note_vec))
    files <- length(grep("File:", note_vec))
    recording <- any(grepl("Status: ALL CLEAR - ready to record", note_vec))

    if (mic_fails > MIC_FAIL_THRESHOLD && files < MIN_FILES_THRESHOLD) {
      output$Active[i] <- "N"
    } else if (mic_fails > MIC_FAIL_THRESHOLD || isFALSE(recording)) {
      output$Active[i] <- "N"
    } else {
      output$Active[i] <- "Y"
    }
  }

  output$Date <- as.Date(output$Date)
  # Replace any remaining NAs in Active column with "N"
  output$Active[is.na(output$Active)] <- "N"
  output$Log_Count <- ifelse(output$Active == "Y", 1, 0)

  # Aggregate by Date and Location (handles duplicates if multiple logs per day)
  output <- output[, c("Date", "Location", "Log_Count")]
  output <- stats::aggregate(Log_Count ~ Date + Location, data = output, FUN = max)

  return(output)
}

#' Fill Gaps in Activity Data
#'
#' Creates a complete date range across all locations and fills in missing dates
#' with Log_Count = 0. This ensures every location has an entry for every date
#' in the monitoring period.
#'
#' @param active_dates Data.frame with Date, Location, and Log_Count columns.
#' @param monitoring_start Character or Date. Optional start date (format: 'YYYY-MM-DD').
#'   If NULL, uses earliest date in active_dates.
#' @param monitoring_end Character or Date. Optional end date (format: 'YYYY-MM-DD').
#'   If NULL, uses latest date in active_dates.
#'
#' @return Data.frame with complete date Ã— location grid, missing dates filled with Log_Count = 0.
#'
#' @keywords internal
.gap_generator <- function(active_dates, monitoring_start, monitoring_end) {
  if (is.null(monitoring_start)) {
    monitoring_start <- min(unique(active_dates$Date))
  } else {
    monitoring_start <- as.Date(monitoring_start)
  }

  if (is.null(monitoring_end)) {
    monitoring_end <- max(unique(active_dates$Date))
  } else {
    monitoring_end <- as.Date(monitoring_end)
  }

  sites <- as.data.frame(unique(active_dates$Location))
  colnames(sites) <- c("Location")
  date_range <- as.data.frame(rep(seq(as.Date(monitoring_start), as.Date(monitoring_end), by = 1),
    each = length(sites$Location)
  ))
  colnames(date_range) <- c("Date")
  sites <- do.call("rbind", replicate(length(unique(date_range$Date)), sites, simplify = FALSE))
  date_range <- cbind(date_range, sites)
  active_dates <- merge(date_range, active_dates, all.x = TRUE)
  active_dates$Log_Count[is.na(active_dates$Log_Count)] <- 0

  return(active_dates)
}
